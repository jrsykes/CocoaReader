# -*- coding: utf-8 -*-
"""Detectron2 cocoa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16pMZwNulV-G21CcLATBaG6AU1yTOJLAY

# Install detectron2
"""

#!pip install pyyaml==5.1
# This is the current pytorch version on Colab. Uncomment this if Colab changes its pytorch version
#!pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html

# Install detectron2 that matches the above pytorch version
# See https://detectron2.readthedocs.io/tutorials/install.html for instructions
#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html
#exit(0)  # After installation, you need to "restart runtime" in Colab. This line can also restart runtime

# check pytorch installation: 
#import torch, torchvision
#print(torch.__version__, torch.cuda.is_available())
##assert torch.__version__.startswith("1.9")   # please manually install torch 1.9 if Colab changes its default version#

## Some basic setup:
## Setup detectron2 logger
#import detectron2
#from detectron2.utils.logger import setup_logger
#setup_logger()#

## import some common libraries
#import numpy as np
#import os, json, cv2, random
#from google.colab.patches import cv2_imshow#

## import some common detectron2 utilities
#from detectron2 import model_zoo
#from detectron2.engine import DefaultPredictor
#from detectron2.config import get_cfg
#from detectron2.utils.visualizer import Visualizer
#from detectron2.data import MetadataCatalog, DatasetCatalog


# check pytorch installation: 
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())
import os, json, cv2, random
#change to the directory where the data is stored
os.chdir('/home/userfs/j/jrs596/scripts')
# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

import numpy as np

from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog
from pycocotools.coco import COCO

from detectron2.data.datasets import register_coco_instances
from detectron2.engine import DefaultTrainer

"""# Train on a custom dataset

In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.

We use [the balloon segmentation dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon)
which only has one class: balloon.
We'll train a balloon segmentation model from an existing model pre-trained on COCO dataset, available in detectron2's model zoo.

Note that COCO dataset does not have the "balloon" category. We'll be able to recognize this new class in a few minutes.

## Prepare the dataset

Register the balloon dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).
Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details.
"""

#from google.colab import drive
#drive.mount('/content/drive')

root='/local/scratch/jrs596/dat/MaskRCNN/dat/results'

register_coco_instances("my_dataset_train", {}, root + "/annotations/train_combined_instances_default.json", root + "/images/train")
register_coco_instances("my_dataset_val", {}, root + "/annotations/val_combined_instances_default.json", root + "images/val")

pod_metadata = MetadataCatalog.get("my_dataset_train")

"""To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:

## Train!

Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~2 minutes to train 300 iterations on a P100 GPU.
"""



cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("my_dataset_train",)
cfg.DATASETS.TEST = ("my_dataset_val",)
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")  # Let training initialize from model zoo
#cfg.MODEL.WEIGHTS = '/local/scratch/jrs596/ResNetFung50_Torch/models/archive/data.pkl'
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR
cfg.SOLVER.MAX_ITER = 10000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset
cfg.SOLVER.STEPS = []        # do not decay learning rate
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)
# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()

torch.save(trainer.model, '/local/scratch/jrs596/Detectron2/models')
# Commented out IPython magic to ensure Python compatibility.
# Look at training curves in tensorboard:
#%load_ext tensorboard
#%tensorboard --logdir output

"""## Inference & evaluation using the trained model
Now, let's run inference with the trained model on the balloon validation dataset. First, let's create a predictor using the model we just trained:


"""

# Inference should use the config with parameters that are used in training
# cfg now already contains everything we've set previously. We changed it a little bit for inference:
#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")  # path to the model we just trained
#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold
#predictor = DefaultPredictor(cfg)#

#"""Then, we randomly select several samples to visualize the prediction results."""#

#from detectron2.utils.visualizer import ColorMode
##dataset_dicts = get_balloon_dicts("balloon/val")
##for d in random.sample(dataset_dicts, 3):    
#im = cv2.imread("/local/scratch/jrs596/MaskRCNN/dat/results/images/val/BPR1645087278.11426674.jpeg")
#outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format
#v = Visualizer(im[:, :, ::-1],
#                   metadata=pod_metadata, 
#                   scale=0.5, 
#                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models
#    )
#out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
#cv2_imshow(out.get_image()[:, :, ::-1])#

#"""We can also evaluate its performance using AP metric implemented in COCO API.
#This gives an AP of ~70. Not bad!
#"""#

#from detectron2.evaluation import COCOEvaluator, inference_on_dataset
#from detectron2.data import build_detection_test_loader
#evaluator = COCOEvaluator("my_dataset_val", output_dir="./output")
#val_loader = build_detection_test_loader(cfg, "my_dataset_val")
#print(inference_on_dataset(predictor.model, val_loader, evaluator))
## another equivalent way to evaluate the model is to use `trainer.test`